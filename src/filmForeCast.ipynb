{
 "cells": [
  {
   "cell_type": "code",
   "id": "addadea1-cb3c-4a76-b5bb-12eb1950fe4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:00.730041Z",
     "start_time": "2025-08-05T11:06:54.173692Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"../Database/Dataset.csv\")\n",
    "df_raw = df.copy()  # Keep a backup of the original dataset"
   ],
   "outputs": [],
   "execution_count": 243
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:00.736508Z",
     "start_time": "2025-08-05T11:07:00.734149Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "6b15adb25f1b509d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1266348, 24)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 244
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:00.745812Z",
     "start_time": "2025-08-05T11:07:00.744144Z"
    }
   },
   "cell_type": "code",
   "source": "print(df.columns.tolist())",
   "id": "de8a9825dc2fba0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'vote_average', 'vote_count', 'status', 'release_date', 'revenue', 'runtime', 'adult', 'backdrop_path', 'budget', 'homepage', 'imdb_id', 'original_language', 'original_title', 'overview', 'popularity', 'poster_path', 'tagline', 'genres', 'production_companies', 'production_countries', 'spoken_languages', 'keywords']\n"
     ]
    }
   ],
   "execution_count": 245
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:01.403048Z",
     "start_time": "2025-08-05T11:07:00.811088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initial Data Cleaning - Remove Columns with Too Many Null Values\n",
    "\n",
    "# 1. Threshold setzen ( hier 50 % )\n",
    "# Falls eine Spalte mehr als 50 % Null Values hat, wird sie deleted.\n",
    "# Es bleiben nur Cols, die weniger als 50 % Null Values haben.\n",
    "threshold = len(df) * 0.5\n",
    "\n",
    "# Zähle die Null values pro Spalte\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "\n",
    "# 2. Spalten ermitteln, bei denen null_counts > threshold\n",
    "cols_to_drop = null_counts[null_counts > threshold].index.tolist()\n",
    "\n",
    "# 3. Spalten löschen\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "print(\"Original shape:\", df_raw.shape)\n",
    "print(\"Cleaned shape:\", df.shape)\n",
    "print(\"----------------------------------------\\n\")\n",
    "\n",
    "# To Checken was gedropped wurde:\n",
    "# dropped_cols als Set Difference\n",
    "dropped_cols = set(df_raw.columns) - set(df.columns)\n",
    "print(\"Dropped columns:\", dropped_cols)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Remaining columns:\", df.columns.tolist())"
   ],
   "id": "291ee682c778f75b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1266348, 24)\n",
      "Cleaned shape: (1266348, 19)\n",
      "----------------------------------------\n",
      "\n",
      "Dropped columns: {'production_companies', 'backdrop_path', 'keywords', 'homepage', 'tagline'}\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Remaining columns: ['id', 'title', 'vote_average', 'vote_count', 'status', 'release_date', 'revenue', 'runtime', 'adult', 'budget', 'imdb_id', 'original_language', 'original_title', 'overview', 'popularity', 'poster_path', 'genres', 'production_countries', 'spoken_languages']\n"
     ]
    }
   ],
   "execution_count": 246
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:01.445393Z",
     "start_time": "2025-08-05T11:07:01.407931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Second Data Cleaning\n",
    "# Wir Droppen die Spalten, die wir nicht brauchen\n",
    "\n",
    "cols_to_drop_for_model = [\n",
    "    'id',\n",
    "    'title',\n",
    "    'original_title',\n",
    "    'imdb_id',\n",
    "    'poster_path',\n",
    "    'overview',\n",
    "    'vote_average',\n",
    "    'production_countries', # already using original language and genres\n",
    "    'spoken_languages' # already using original language\n",
    "]\n",
    "\n",
    "features = df.drop(columns=cols_to_drop_for_model)\n",
    "target = df['vote_average']\n",
    "\n",
    "\n",
    "\n",
    "print(\"Original DataFrame:\", df.shape)\n",
    "print(\"Features DataFrame:\", features.shape)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"The Features we are going to be using:\", features.columns.tolist())\n",
    "\n"
   ],
   "id": "1c28be1c47ae3acd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame: (1266348, 19)\n",
      "Features DataFrame: (1266348, 10)\n",
      "-------------------------------------------\n",
      "The Features we are going to be using: ['vote_count', 'status', 'release_date', 'revenue', 'runtime', 'adult', 'budget', 'original_language', 'popularity', 'genres']\n"
     ]
    }
   ],
   "execution_count": 247
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:01.522971Z",
     "start_time": "2025-08-05T11:07:01.450191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check values in different columns\n",
    "\n",
    "#print(df['status'].value_counts(dropna=False))\n",
    "#print(df['adult'].value_counts(dropna=False))\n",
    "#print(df['original_language'].value_counts())\n",
    "df['genres'].describe()"
   ],
   "id": "b22225652f343eab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          733267\n",
       "unique          14126\n",
       "top       Documentary\n",
       "freq           147108\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 248
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:07.481104Z",
     "start_time": "2025-08-05T11:07:01.543954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# https://stackoverflow.com/questions/58033652/separating-categories-within-one-column-in-my-dataframe?utm_source=chatgpt.com\n",
    "\n",
    "def extract_genres(genre_str):\n",
    "    try:\n",
    "        genres = ast.literal_eval(genre_str)\n",
    "        return [g['name'] for g in genres]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df['genre_list'] = df['genres'].apply(extract_genres)\n",
    "\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_genres = pd.DataFrame(\n",
    "    mlb.fit_transform(df['genre_list']),\n",
    "    columns=[f\"has_{g}\" for g in mlb.classes_],\n",
    "    index=df.index\n",
    ")\n",
    "df = pd.concat([df, df_genres], axis=1)"
   ],
   "id": "5c014393960d5114",
   "outputs": [],
   "execution_count": 249
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:08.376050Z",
     "start_time": "2025-08-05T11:07:07.497817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature Engineering\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Convert vote_count using logarithmic scaling\n",
    "# prevents extreme large values\n",
    "df['vote_count_log'] = np.log1p(df['vote_count'])\n",
    "\n",
    "# Use One Hot Encoding for the STATUS\n",
    "df['status_released'] = (df['status'] == 'Released').astype(int)\n",
    "# By Far the majority of movies are Released -> Binary Choice\n",
    "# 1 : Released, 0 : Not Released\n",
    "\n",
    "\n",
    "# Convert 'release_date' to datetime and extract the YEAR\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "# coerce -> If parsing fails, set the value to NaT (Not a Time)\n",
    "df['release_year'] = df['release_date'].dt.year\n",
    "df['release_year'] = df['release_year'].clip(upper=2025).clip(lower=1900)\n",
    "\n",
    "# Normalize BUDGET and REVENUE\n",
    "# Fill NaN values with 0 for budget and revenue\n",
    "df['budget'] = df['budget'].fillna(0)\n",
    "df['revenue'] = df['revenue'].fillna(0)\n",
    "\n",
    "# Scale budget and revenue between 0 and 1\n",
    "df[['budget_scaled', 'revenue_scaled']] = scaler.fit_transform(df[['budget', 'revenue']])\n",
    "\n",
    "\n",
    "# Convert RUNTIME to numeric, fill NaN with median\n",
    "df['runtime'] = df['runtime'].fillna(df['runtime'].median())\n",
    "df[['runtime_scaled']] = scaler.fit_transform(df[['runtime']])\n",
    "\n",
    "\n",
    "# Convert ADULT to binary (1 for True, 0 for False)\n",
    "# actually is statistically releveant, as almost 10 % are adult movies\n",
    "df['adult'] = df['adult'].astype(bool).astype(int)\n",
    "\n",
    "\n",
    "# One Hot Encoding for ORIGINAL_LANGUAGE\n",
    "df = pd.get_dummies(df, columns=['original_language'], prefix='lang', drop_first=True)\n",
    "\n",
    "\n",
    "# Min Max Scaling for POPULARITY\n",
    "df[['popularity_scaled']] = scaler.fit_transform(df[['popularity']])\n",
    "\n",
    "\n",
    "# Extracting features for genres with MultiLabelBinarizer in function above\n",
    "genre_features = [col for col in df.columns if col.startswith('has_')]\n",
    "\n",
    "# Final list of features\n",
    "feature_cols = [\n",
    "    'vote_count_log',\n",
    "    'status_released',\n",
    "    'release_year',\n",
    "    'budget_scaled',\n",
    "    'revenue_scaled',\n",
    "    'runtime_scaled',\n",
    "    'adult',\n",
    "    'popularity_scaled',\n",
    "    #'spoken_languages' — handled separately\n",
    "] + genre_features + [col for col in df.columns if col.startswith('lang_')]\n",
    "\n",
    "\n",
    "features = df[feature_cols]\n",
    "#target = df['vote_average']\n",
    "\n",
    "\n",
    "\n",
    "# fill the Not a Number values with 0\n",
    "features = features.fillna(0)"
   ],
   "id": "b1d8e065-73e0-4d1f-8e13-30f522858357",
   "outputs": [],
   "execution_count": 250
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:08.765815Z",
     "start_time": "2025-08-05T11:07:08.378871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split Data into Training, Validation, and Test Sets\n",
    "# We will use 70% for training, 20% for validation, 10% for tests\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "\n",
    "# Splitting the Data into train and temporary sets (70% train, 30% temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    # X_train : features\n",
    "    # X_temp : also features, 30 percent of the data\n",
    "    # y_train : target\n",
    "    # y_temp : still 30 percent of the data, but not features -> target values\n",
    "    features, target,\n",
    "    test_size=0.30,\n",
    "    )\n",
    "\n",
    "# Splitting the Temp set into validation and test sets (50% of temp each)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=1/3,\n",
    ")\n",
    "\n",
    "\n"
   ],
   "id": "73e95fd983f614e1",
   "outputs": [],
   "execution_count": 251
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:08.773233Z",
     "start_time": "2025-08-05T11:07:08.770862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "print(\"Training target shape:\", y_train.shape)\n",
    "print(\"Validation target shape:\", y_val.shape)\n",
    "print(\"Test target shape:\", y_test.shape)\n"
   ],
   "id": "676b4bd04a02f89f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (886443, 183)\n",
      "Validation set shape: (253270, 183)\n",
      "Test set shape: (126635, 183)\n",
      "Training target shape: (886443,)\n",
      "Validation target shape: (253270,)\n",
      "Test target shape: (126635,)\n"
     ]
    }
   ],
   "execution_count": 252
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:08.855788Z",
     "start_time": "2025-08-05T11:07:08.779437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for object (non-numeric) dtypes\n",
    "print(features.dtypes[features.dtypes == 'object'])\n",
    "\n",
    "# Check for missing values\n",
    "print(\"NaNs in features:\", features.isna().sum().sum())\n",
    "print(\"NaNs in target:\", target.isna().sum())"
   ],
   "id": "9e5ae133caafb087",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: object)\n",
      "NaNs in features: 0\n",
      "NaNs in target: 0\n"
     ]
    }
   ],
   "execution_count": 253
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:13.120805Z",
     "start_time": "2025-08-05T11:07:08.860143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "# import model to be used\n",
    "model = LinearRegression()\n",
    "\n",
    "# by fit -> train model on data set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# produce a prediction on validation and test sets\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Look at the performance\n",
    "\n",
    "# R² score\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"📊 Validation R2:\", r2_val)\n",
    "print(\"----------------------\")\n",
    "print(\"📊 Test R2:\", r2_test)\n",
    "print(\"----------------------\")\n",
    "print(\"📉 Validation MSE:\", mse_val)\n",
    "print(\"----------------------\")\n",
    "print(\"📉 Test MSE:\", mse_test)\n",
    "print(\"----------------------\")"
   ],
   "id": "4dd36c906333cb5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation R2: 0.48586217330126347\n",
      "----------------------\n",
      "📊 Test R2: 0.4883999483580138\n",
      "----------------------\n",
      "📉 Validation MSE: 4.4539062880351\n",
      "----------------------\n",
      "📉 Test MSE: 4.418847851586559\n",
      "----------------------\n"
     ]
    }
   ],
   "execution_count": 254
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:13.151844Z",
     "start_time": "2025-08-05T11:07:13.126845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Create a DataFrame with predictions, actuals, and titles\n",
    "results = pd.DataFrame({\n",
    "\n",
    "    # take the correct movie title\n",
    "    'title': df.loc[X_test.index, 'title'],\n",
    "\n",
    "    'predicted_rating': y_test_pred,\n",
    "\n",
    "    'actual_rating': y_test\n",
    "})\n",
    "\n",
    "# Round values for easier reading\n",
    "results['predicted_rating'] = results['predicted_rating'].round(2)\n",
    "results['actual_rating'] = results['actual_rating'].round(2)\n",
    "\n",
    "res_non_zero = results[results['actual_rating'] > 0]\n",
    "\n",
    "# Show a random sample of 15 movies\n",
    "sample_results = res_non_zero.sample(20, random_state=42)\n",
    "\n",
    "display(sample_results)"
   ],
   "id": "12975a797b3afdff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               title  predicted_rating  \\\n",
       "91105                       Letters from My Windmill              5.54   \n",
       "129045                                      Route 10              4.13   \n",
       "248900                          Venezuela Jungle Jam              2.24   \n",
       "279007                               Sacred Journeys              2.22   \n",
       "59871                                        DriverX              6.20   \n",
       "202552                                 Bird Watchers              2.91   \n",
       "227246  Keny Arkana - Concert en Direct de Marseille              2.41   \n",
       "317777                         Elephants on a Cobweb              2.48   \n",
       "229779                                 Afternoon Tea              2.27   \n",
       "64450                                 Guns of Diablo              5.91   \n",
       "158654                                   Prem Granth              3.73   \n",
       "258880                              Beyond Suspicion              2.28   \n",
       "46339                            The Memory of Water              7.23   \n",
       "9886                                      The Dinner             11.09   \n",
       "17901                                      As Needed              9.79   \n",
       "44080                                  Virginia City              7.02   \n",
       "94156           Billy Connolly: High Horse Tour Live              4.92   \n",
       "303930                        La Femme Nikita Denise              2.31   \n",
       "345107         Don't Get Mad... I Fucked Your Dad! 4              2.34   \n",
       "316898                                After Midnight              2.28   \n",
       "\n",
       "        actual_rating  \n",
       "91105            6.80  \n",
       "129045           4.60  \n",
       "248900          10.00  \n",
       "279007           1.00  \n",
       "59871            6.50  \n",
       "202552          10.00  \n",
       "227246          10.00  \n",
       "317777           7.00  \n",
       "229779           8.00  \n",
       "64450            5.27  \n",
       "158654           6.70  \n",
       "258880          10.00  \n",
       "46339            6.30  \n",
       "9886             4.50  \n",
       "17901            6.76  \n",
       "44080            5.90  \n",
       "94156            7.00  \n",
       "303930           6.00  \n",
       "345107           7.00  \n",
       "316898           3.00  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>actual_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91105</th>\n",
       "      <td>Letters from My Windmill</td>\n",
       "      <td>5.54</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129045</th>\n",
       "      <td>Route 10</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248900</th>\n",
       "      <td>Venezuela Jungle Jam</td>\n",
       "      <td>2.24</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279007</th>\n",
       "      <td>Sacred Journeys</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59871</th>\n",
       "      <td>DriverX</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202552</th>\n",
       "      <td>Bird Watchers</td>\n",
       "      <td>2.91</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227246</th>\n",
       "      <td>Keny Arkana - Concert en Direct de Marseille</td>\n",
       "      <td>2.41</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317777</th>\n",
       "      <td>Elephants on a Cobweb</td>\n",
       "      <td>2.48</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229779</th>\n",
       "      <td>Afternoon Tea</td>\n",
       "      <td>2.27</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64450</th>\n",
       "      <td>Guns of Diablo</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158654</th>\n",
       "      <td>Prem Granth</td>\n",
       "      <td>3.73</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258880</th>\n",
       "      <td>Beyond Suspicion</td>\n",
       "      <td>2.28</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46339</th>\n",
       "      <td>The Memory of Water</td>\n",
       "      <td>7.23</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9886</th>\n",
       "      <td>The Dinner</td>\n",
       "      <td>11.09</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17901</th>\n",
       "      <td>As Needed</td>\n",
       "      <td>9.79</td>\n",
       "      <td>6.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44080</th>\n",
       "      <td>Virginia City</td>\n",
       "      <td>7.02</td>\n",
       "      <td>5.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94156</th>\n",
       "      <td>Billy Connolly: High Horse Tour Live</td>\n",
       "      <td>4.92</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303930</th>\n",
       "      <td>La Femme Nikita Denise</td>\n",
       "      <td>2.31</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345107</th>\n",
       "      <td>Don't Get Mad... I Fucked Your Dad! 4</td>\n",
       "      <td>2.34</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316898</th>\n",
       "      <td>After Midnight</td>\n",
       "      <td>2.28</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 255
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:07:13.159311Z",
     "start_time": "2025-08-05T11:07:13.157906Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "abfc1b68eed7096e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
