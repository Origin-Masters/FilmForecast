{
 "cells": [
  {
   "cell_type": "code",
   "id": "addadea1-cb3c-4a76-b5bb-12eb1950fe4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:27.263721Z",
     "start_time": "2025-08-05T13:33:20.333557Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df = pd.read_csv(\"../Database/Dataset.csv\")\n",
    "df_raw = df.copy()  # Keep a backup of the original dataset"
   ],
   "outputs": [],
   "execution_count": 268
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:27.276342Z",
     "start_time": "2025-08-05T13:33:27.273372Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "6b15adb25f1b509d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1266348, 24)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 269
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:27.284204Z",
     "start_time": "2025-08-05T13:33:27.281823Z"
    }
   },
   "cell_type": "code",
   "source": "print(df.columns.tolist())",
   "id": "de8a9825dc2fba0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'vote_average', 'vote_count', 'status', 'release_date', 'revenue', 'runtime', 'adult', 'backdrop_path', 'budget', 'homepage', 'imdb_id', 'original_language', 'original_title', 'overview', 'popularity', 'poster_path', 'tagline', 'genres', 'production_companies', 'production_countries', 'spoken_languages', 'keywords']\n"
     ]
    }
   ],
   "execution_count": 270
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:27.869232Z",
     "start_time": "2025-08-05T13:33:27.289289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initial Data Cleaning - Remove Columns with Too Many Null Values\n",
    "\n",
    "# 1. Threshold setzen ( hier 50 % )\n",
    "# Falls eine Spalte mehr als 50 % Null Values hat, wird sie deleted.\n",
    "# Es bleiben nur Cols, die weniger als 50 % Null Values haben.\n",
    "threshold = len(df) * 0.5\n",
    "\n",
    "# Zähle die Null values pro Spalte\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "\n",
    "# 2. Spalten ermitteln, bei denen null_counts > threshold\n",
    "cols_to_drop = null_counts[null_counts > threshold].index.tolist()\n",
    "\n",
    "# 3. Spalten löschen\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "print(\"Original shape:\", df_raw.shape)\n",
    "print(\"Cleaned shape:\", df.shape)\n",
    "print(\"----------------------------------------\\n\")\n",
    "\n",
    "# To Checken was gedropped wurde:\n",
    "# dropped_cols als Set Difference\n",
    "dropped_cols = set(df_raw.columns) - set(df.columns)\n",
    "print(\"Dropped columns:\", dropped_cols)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Remaining columns:\", df.columns.tolist())"
   ],
   "id": "291ee682c778f75b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1266348, 24)\n",
      "Cleaned shape: (1266348, 19)\n",
      "----------------------------------------\n",
      "\n",
      "Dropped columns: {'production_companies', 'backdrop_path', 'keywords', 'homepage', 'tagline'}\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Remaining columns: ['id', 'title', 'vote_average', 'vote_count', 'status', 'release_date', 'revenue', 'runtime', 'adult', 'budget', 'imdb_id', 'original_language', 'original_title', 'overview', 'popularity', 'poster_path', 'genres', 'production_countries', 'spoken_languages']\n"
     ]
    }
   ],
   "execution_count": 271
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:27.914337Z",
     "start_time": "2025-08-05T13:33:27.873182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Second Data Cleaning\n",
    "# Wir Droppen die Spalten, die wir nicht brauchen\n",
    "\n",
    "cols_to_drop_for_model = [\n",
    "    'id',\n",
    "    'title',\n",
    "    'original_title',\n",
    "    'imdb_id',\n",
    "    'poster_path',\n",
    "    'overview',\n",
    "    'vote_average',\n",
    "    'production_countries', # already using original language and genres\n",
    "    'spoken_languages' # already using original language\n",
    "]\n",
    "\n",
    "features = df.drop(columns=cols_to_drop_for_model)\n",
    "target = df['vote_average']\n",
    "\n",
    "\n",
    "\n",
    "print(\"Original DataFrame:\", df.shape)\n",
    "print(\"Features DataFrame:\", features.shape)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"The Features we are going to be using:\", features.columns.tolist())\n",
    "\n"
   ],
   "id": "1c28be1c47ae3acd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame: (1266348, 19)\n",
      "Features DataFrame: (1266348, 10)\n",
      "-------------------------------------------\n",
      "The Features we are going to be using: ['vote_count', 'status', 'release_date', 'revenue', 'runtime', 'adult', 'budget', 'original_language', 'popularity', 'genres']\n"
     ]
    }
   ],
   "execution_count": 272
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:27.994502Z",
     "start_time": "2025-08-05T13:33:27.919721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check values in different columns\n",
    "\n",
    "#print(df['status'].value_counts(dropna=False))\n",
    "#print(df['adult'].value_counts(dropna=False))\n",
    "#print(df['original_language'].value_counts())\n",
    "df['genres'].describe()"
   ],
   "id": "b22225652f343eab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          733267\n",
       "unique          14126\n",
       "top       Documentary\n",
       "freq           147108\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 273
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:34.444261Z",
     "start_time": "2025-08-05T13:33:28.017816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# https://stackoverflow.com/questions/58033652/separating-categories-within-one-column-in-my-dataframe?utm_source=chatgpt.com\n",
    "\n",
    "def extract_genres(genre_str):\n",
    "    try:\n",
    "        genres = ast.literal_eval(genre_str)\n",
    "        return [g['name'] for g in genres]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df['genre_list'] = df['genres'].apply(extract_genres)\n",
    "\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_genres = pd.DataFrame(\n",
    "    mlb.fit_transform(df['genre_list']),\n",
    "    columns=[f\"has_{g}\" for g in mlb.classes_],\n",
    "    index=df.index\n",
    ")\n",
    "df = pd.concat([df, df_genres], axis=1)"
   ],
   "id": "5c014393960d5114",
   "outputs": [],
   "execution_count": 274
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:35.547017Z",
     "start_time": "2025-08-05T13:33:34.465896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature Engineering\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Convert vote_count using logarithmic scaling\n",
    "# prevents extreme large values\n",
    "df['vote_count_log'] = np.log1p(df['vote_count'])\n",
    "\n",
    "# Use One Hot Encoding for the STATUS\n",
    "df['status_released'] = (df['status'] == 'Released').astype(int)\n",
    "# By Far the majority of movies are Released -> Binary Choice\n",
    "# 1 : Released, 0 : Not Released\n",
    "\n",
    "\n",
    "# Convert 'release_date' to datetime and extract the YEAR\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "# coerce -> If parsing fails, set the value to NaT (Not a Time)\n",
    "df['release_year'] = df['release_date'].dt.year\n",
    "df['release_year'] = df['release_year'].clip(upper=2025).clip(lower=1900)\n",
    "\n",
    "# Normalize BUDGET and REVENUE\n",
    "# Fill NaN values with 0 for budget and revenue\n",
    "df['budget'] = df['budget'].fillna(0)\n",
    "df['revenue'] = df['revenue'].fillna(0)\n",
    "\n",
    "# Scale budget and revenue between 0 and 1\n",
    "df[['budget_scaled', 'revenue_scaled']] = scaler.fit_transform(df[['budget', 'revenue']])\n",
    "\n",
    "\n",
    "# Convert RUNTIME to numeric, fill NaN with median\n",
    "df['runtime'] = df['runtime'].fillna(df['runtime'].median())\n",
    "df[['runtime_scaled']] = scaler.fit_transform(df[['runtime']])\n",
    "\n",
    "\n",
    "# Convert ADULT to binary (1 for True, 0 for False)\n",
    "# actually is statistically releveant, as almost 10 % are adult movies\n",
    "df['adult'] = df['adult'].astype(bool).astype(int)\n",
    "\n",
    "\n",
    "# One Hot Encoding for ORIGINAL_LANGUAGE\n",
    "df = pd.get_dummies(df, columns=['original_language'], prefix='lang', drop_first=True)\n",
    "\n",
    "\n",
    "# Min Max Scaling for POPULARITY\n",
    "df[['popularity_scaled']] = scaler.fit_transform(df[['popularity']])\n",
    "\n",
    "\n",
    "# Extracting features for genres with MultiLabelBinarizer in function above\n",
    "genre_features = [col for col in df.columns if col.startswith('has_')]\n",
    "\n",
    "# Final list of features\n",
    "feature_cols = [\n",
    "    'vote_count_log',\n",
    "    'status_released',\n",
    "    'release_year',\n",
    "    'budget_scaled',\n",
    "    'revenue_scaled',\n",
    "    'runtime_scaled',\n",
    "    'adult',\n",
    "    'popularity_scaled',\n",
    "    #'spoken_languages' — handled separately\n",
    "] + genre_features + [col for col in df.columns if col.startswith('lang_')]\n",
    "\n",
    "\n",
    "features = df[feature_cols]\n",
    "#target = df['vote_average']\n",
    "\n",
    "\n",
    "\n",
    "# fill the Not a Number values with 0\n",
    "features = features.fillna(0)"
   ],
   "id": "b1d8e065-73e0-4d1f-8e13-30f522858357",
   "outputs": [],
   "execution_count": 275
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:35.952971Z",
     "start_time": "2025-08-05T13:33:35.550323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split Data into Training, Validation, and Test Sets\n",
    "# We will use 70% for training, 20% for validation, 10% for tests\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "\n",
    "# Splitting the Data into train and temporary sets (70% train, 30% temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    # X_train : features\n",
    "    # X_temp : also features, 30 percent of the data\n",
    "    # y_train : target\n",
    "    # y_temp : still 30 percent of the data, but not features -> target values\n",
    "    features, target,\n",
    "    test_size=0.30,\n",
    "    )\n",
    "\n",
    "# Splitting the Temp set into validation and test sets (50% of temp each)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=1/3,\n",
    ")\n",
    "\n",
    "\n"
   ],
   "id": "73e95fd983f614e1",
   "outputs": [],
   "execution_count": 276
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:35.959878Z",
     "start_time": "2025-08-05T13:33:35.957587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "print(\"Training target shape:\", y_train.shape)\n",
    "print(\"Validation target shape:\", y_val.shape)\n",
    "print(\"Test target shape:\", y_test.shape)\n"
   ],
   "id": "676b4bd04a02f89f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (886443, 183)\n",
      "Validation set shape: (253270, 183)\n",
      "Test set shape: (126635, 183)\n",
      "Training target shape: (886443,)\n",
      "Validation target shape: (253270,)\n",
      "Test target shape: (126635,)\n"
     ]
    }
   ],
   "execution_count": 277
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:36.040876Z",
     "start_time": "2025-08-05T13:33:35.965724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for object (non-numeric) dtypes\n",
    "print(features.dtypes[features.dtypes == 'object'])\n",
    "\n",
    "# Check for missing values\n",
    "print(\"NaNs in features:\", features.isna().sum().sum())\n",
    "print(\"NaNs in target:\", target.isna().sum())"
   ],
   "id": "9e5ae133caafb087",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: object)\n",
      "NaNs in features: 0\n",
      "NaNs in target: 0\n"
     ]
    }
   ],
   "execution_count": 278
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:36.461748Z",
     "start_time": "2025-08-05T13:33:36.044458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "\n",
    "# Create Polynomial Features of degree 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "numeric_features = ['vote_count_log', 'budget_scaled', 'revenue_scaled', 'runtime_scaled', 'popularity_scaled']\n",
    "X_train_num = X_train[numeric_features]\n",
    "X_val_num = X_val[numeric_features]\n",
    "X_test_num = X_test[numeric_features]\n",
    "\n",
    "poly = PolynomialFeatures(degree=2,include_bias=False)\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train_num)\n",
    "X_val_poly = poly.transform(X_val_num)\n",
    "X_test_poly = poly.transform(X_test_num)\n",
    "\n",
    "\n",
    "# import model to be used\n",
    "model = LinearRegression()\n",
    "\n",
    "# by fit -> TRAIN model on data set\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# produce a PREDICTION on validation and test sets\n",
    "y_val_pred = model.predict(X_val_poly)\n",
    "y_test_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Look at the performance\n",
    "\n",
    "# R² score\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"📊 Validation R2:\", r2_val)\n",
    "print(\"----------------------\")\n",
    "print(\"📊 Test R2:\", r2_test)\n",
    "print(\"----------------------\")\n",
    "print(\"📉 Validation MSE:\", mse_val)\n",
    "print(\"----------------------\")\n",
    "print(\"📉 Test MSE:\", mse_test)\n",
    "print(\"----------------------\")"
   ],
   "id": "4dd36c906333cb5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Validation R2: 0.682862375791018\n",
      "----------------------\n",
      "📊 Test R2: 0.6661081283617595\n",
      "----------------------\n",
      "📉 Validation MSE: 2.7514282784156125\n",
      "----------------------\n",
      "📉 Test MSE: 2.8967269006055836\n",
      "----------------------\n"
     ]
    }
   ],
   "execution_count": 279
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:36.494305Z",
     "start_time": "2025-08-05T13:33:36.467266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Create a DataFrame with predictions, actuals, and titles\n",
    "results = pd.DataFrame({\n",
    "\n",
    "    # take the correct movie title\n",
    "    'title': df.loc[X_test.index, 'title'],\n",
    "\n",
    "    'predicted_rating': y_test_pred,\n",
    "\n",
    "    'actual_rating': y_test\n",
    "})\n",
    "\n",
    "# Round values for easier reading\n",
    "results['predicted_rating'] = results['predicted_rating'].round(2)\n",
    "results['actual_rating'] = results['actual_rating'].round(2)\n",
    "\n",
    "res_non_zero = results[results['actual_rating'] > 0]\n",
    "\n",
    "# Show a random sample of 15 movies\n",
    "sample_results = res_non_zero.sample(20, random_state=42)\n",
    "\n",
    "display(sample_results)"
   ],
   "id": "12975a797b3afdff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                    title  predicted_rating  \\\n",
       "296517      Bibi Blocksberg: Eene meene eins, zwei, drei!              3.27   \n",
       "183788              Exoplanètes : les chasseurs de mondes              4.82   \n",
       "338935                                                SIX              2.75   \n",
       "236350                                      Blauer Sommer              3.33   \n",
       "219169                                          Raajjiyam              4.74   \n",
       "175051                             Bikkar Bai Sentimental              5.36   \n",
       "259348                                         Specialist              3.26   \n",
       "298004  Pass the Warning: Reflecting on Nic Roeg's Mas...              3.23   \n",
       "139106                                   The Flower Thief              6.10   \n",
       "9689                                         Blood & Gold              6.93   \n",
       "280820                                  No Sin Unpunished              3.28   \n",
       "74286                       When Christmas Trees Light Up              8.02   \n",
       "224111                                           Solo Rex              4.82   \n",
       "43103                                     Plato's Academy              8.18   \n",
       "145102                                       C(us)todians              6.06   \n",
       "157755                                             Nights              5.51   \n",
       "314592  Hcup Godly Body Is Dyed With Cum For The First...              3.22   \n",
       "288944                              L'Esprit Le Corbusier              3.33   \n",
       "15086                                              United              7.16   \n",
       "228031                                           Thin Air              3.26   \n",
       "\n",
       "        actual_rating  \n",
       "296517           6.50  \n",
       "183788           7.50  \n",
       "338935           7.00  \n",
       "236350          10.00  \n",
       "219169           5.50  \n",
       "175051           7.70  \n",
       "259348           6.00  \n",
       "298004           7.00  \n",
       "139106           8.80  \n",
       "9689             6.69  \n",
       "280820           6.00  \n",
       "74286            7.30  \n",
       "224111           6.00  \n",
       "43103            7.10  \n",
       "145102           6.00  \n",
       "157755           5.00  \n",
       "314592           8.00  \n",
       "288944           6.00  \n",
       "15086            7.00  \n",
       "228031           5.00  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>actual_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>296517</th>\n",
       "      <td>Bibi Blocksberg: Eene meene eins, zwei, drei!</td>\n",
       "      <td>3.27</td>\n",
       "      <td>6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183788</th>\n",
       "      <td>Exoplanètes : les chasseurs de mondes</td>\n",
       "      <td>4.82</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338935</th>\n",
       "      <td>SIX</td>\n",
       "      <td>2.75</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236350</th>\n",
       "      <td>Blauer Sommer</td>\n",
       "      <td>3.33</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219169</th>\n",
       "      <td>Raajjiyam</td>\n",
       "      <td>4.74</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175051</th>\n",
       "      <td>Bikkar Bai Sentimental</td>\n",
       "      <td>5.36</td>\n",
       "      <td>7.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259348</th>\n",
       "      <td>Specialist</td>\n",
       "      <td>3.26</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298004</th>\n",
       "      <td>Pass the Warning: Reflecting on Nic Roeg's Mas...</td>\n",
       "      <td>3.23</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139106</th>\n",
       "      <td>The Flower Thief</td>\n",
       "      <td>6.10</td>\n",
       "      <td>8.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>Blood &amp; Gold</td>\n",
       "      <td>6.93</td>\n",
       "      <td>6.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280820</th>\n",
       "      <td>No Sin Unpunished</td>\n",
       "      <td>3.28</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74286</th>\n",
       "      <td>When Christmas Trees Light Up</td>\n",
       "      <td>8.02</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224111</th>\n",
       "      <td>Solo Rex</td>\n",
       "      <td>4.82</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43103</th>\n",
       "      <td>Plato's Academy</td>\n",
       "      <td>8.18</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145102</th>\n",
       "      <td>C(us)todians</td>\n",
       "      <td>6.06</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157755</th>\n",
       "      <td>Nights</td>\n",
       "      <td>5.51</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314592</th>\n",
       "      <td>Hcup Godly Body Is Dyed With Cum For The First...</td>\n",
       "      <td>3.22</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288944</th>\n",
       "      <td>L'Esprit Le Corbusier</td>\n",
       "      <td>3.33</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15086</th>\n",
       "      <td>United</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228031</th>\n",
       "      <td>Thin Air</td>\n",
       "      <td>3.26</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 280
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T13:33:36.500717Z",
     "start_time": "2025-08-05T13:33:36.498853Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "abfc1b68eed7096e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
