{
 "cells": [
  {
   "cell_type": "code",
   "id": "addadea1-cb3c-4a76-b5bb-12eb1950fe4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:45.488063Z",
     "start_time": "2025-08-05T10:50:38.991Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"../Database/Dataset.csv\")\n",
    "df_raw = df.copy()  # Keep a backup of the original dataset"
   ],
   "outputs": [],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:45.494777Z",
     "start_time": "2025-08-05T10:50:45.492476Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "6b15adb25f1b509d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1266348, 24)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:45.563334Z",
     "start_time": "2025-08-05T10:50:45.561099Z"
    }
   },
   "cell_type": "code",
   "source": "print(df.columns.tolist())",
   "id": "de8a9825dc2fba0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'vote_average', 'vote_count', 'status', 'release_date', 'revenue', 'runtime', 'adult', 'backdrop_path', 'budget', 'homepage', 'imdb_id', 'original_language', 'original_title', 'overview', 'popularity', 'poster_path', 'tagline', 'genres', 'production_companies', 'production_countries', 'spoken_languages', 'keywords']\n"
     ]
    }
   ],
   "execution_count": 206
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:46.200632Z",
     "start_time": "2025-08-05T10:50:45.627918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initial Data Cleaning - Remove Columns with Too Many Null Values\n",
    "\n",
    "# 1. Threshold setzen ( hier 50 % )\n",
    "# Falls eine Spalte mehr als 50 % Null Values hat, wird sie deleted.\n",
    "# Es bleiben nur Cols, die weniger als 50 % Null Values haben.\n",
    "threshold = len(df) * 0.5\n",
    "\n",
    "# ZÃ¤hle die Null values pro Spalte\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "\n",
    "# 2. Spalten ermitteln, bei denen null_counts > threshold\n",
    "cols_to_drop = null_counts[null_counts > threshold].index.tolist()\n",
    "\n",
    "# 3. Spalten lÃ¶schen\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "print(\"Original shape:\", df_raw.shape)\n",
    "print(\"Cleaned shape:\", df.shape)\n",
    "print(\"----------------------------------------\\n\")\n",
    "\n",
    "# To Checken was gedropped wurde:\n",
    "# dropped_cols als Set Difference\n",
    "dropped_cols = set(df_raw.columns) - set(df.columns)\n",
    "print(\"Dropped columns:\", dropped_cols)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Remaining columns:\", df.columns.tolist())"
   ],
   "id": "291ee682c778f75b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1266348, 24)\n",
      "Cleaned shape: (1266348, 19)\n",
      "----------------------------------------\n",
      "\n",
      "Dropped columns: {'production_companies', 'backdrop_path', 'keywords', 'homepage', 'tagline'}\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Remaining columns: ['id', 'title', 'vote_average', 'vote_count', 'status', 'release_date', 'revenue', 'runtime', 'adult', 'budget', 'imdb_id', 'original_language', 'original_title', 'overview', 'popularity', 'poster_path', 'genres', 'production_countries', 'spoken_languages']\n"
     ]
    }
   ],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:46.276586Z",
     "start_time": "2025-08-05T10:50:46.236175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Second Data Cleaning\n",
    "# Wir Droppen die Spalten, die wir nicht brauchen\n",
    "\n",
    "cols_to_drop_for_model = [\n",
    "    'id',\n",
    "    'title',\n",
    "    'original_title',\n",
    "    'imdb_id',\n",
    "    'poster_path',\n",
    "    'overview',\n",
    "    'vote_average',\n",
    "    'production_countries', # already using original language and genres\n",
    "    'spoken_languages' # already using original language\n",
    "]\n",
    "\n",
    "features = df.drop(columns=cols_to_drop_for_model)\n",
    "target = df['vote_average']\n",
    "\n",
    "\n",
    "\n",
    "print(\"Original DataFrame:\", df.shape)\n",
    "print(\"Features DataFrame:\", features.shape)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"The Features we are going to be using:\", features.columns.tolist())\n",
    "\n"
   ],
   "id": "1c28be1c47ae3acd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame: (1266348, 19)\n",
      "Features DataFrame: (1266348, 10)\n",
      "-------------------------------------------\n",
      "The Features we are going to be using: ['vote_count', 'status', 'release_date', 'revenue', 'runtime', 'adult', 'budget', 'original_language', 'popularity', 'genres']\n"
     ]
    }
   ],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:46.358073Z",
     "start_time": "2025-08-05T10:50:46.282357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check values in different columns\n",
    "\n",
    "#print(df['status'].value_counts(dropna=False))\n",
    "#print(df['adult'].value_counts(dropna=False))\n",
    "#print(df['original_language'].value_counts())\n",
    "df['genres'].describe()"
   ],
   "id": "b22225652f343eab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          733267\n",
       "unique          14126\n",
       "top       Documentary\n",
       "freq           147108\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 209
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:52.268995Z",
     "start_time": "2025-08-05T10:50:46.380334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# https://stackoverflow.com/questions/58033652/separating-categories-within-one-column-in-my-dataframe?utm_source=chatgpt.com\n",
    "\n",
    "def extract_genres(genre_str):\n",
    "    try:\n",
    "        genres = ast.literal_eval(genre_str)\n",
    "        return [g['name'] for g in genres]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df['genre_list'] = df['genres'].apply(extract_genres)\n",
    "\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_genres = pd.DataFrame(\n",
    "    mlb.fit_transform(df['genre_list']),\n",
    "    columns=[f\"has_{g}\" for g in mlb.classes_],\n",
    "    index=df.index\n",
    ")\n",
    "df = pd.concat([df, df_genres], axis=1)"
   ],
   "id": "5c014393960d5114",
   "outputs": [],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:53.175739Z",
     "start_time": "2025-08-05T10:50:52.284888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature Engineering\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Convert vote_count using logarithmic scaling\n",
    "# prevents extreme large values\n",
    "df['vote_count_log'] = np.log1p(df['vote_count'])\n",
    "\n",
    "# Use One Hot Encoding for the STATUS\n",
    "df['status_released'] = (df['status'] == 'Released').astype(int)\n",
    "# By Far the majority of movies are Released -> Binary Choice\n",
    "# 1 : Released, 0 : Not Released\n",
    "\n",
    "\n",
    "# Convert 'release_date' to datetime and extract the YEAR\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "# coerce -> If parsing fails, set the value to NaT (Not a Time)\n",
    "df['release_year'] = df['release_date'].dt.year\n",
    "df['release_year'] = df['release_year'].clip(upper=2025).clip(lower=1900)\n",
    "\n",
    "# Normalize BUDGET and REVENUE\n",
    "# Fill NaN values with 0 for budget and revenue\n",
    "df['budget'] = df['budget'].fillna(0)\n",
    "df['revenue'] = df['revenue'].fillna(0)\n",
    "\n",
    "# Scale budget and revenue between 0 and 1\n",
    "df[['budget_scaled', 'revenue_scaled']] = scaler.fit_transform(df[['budget', 'revenue']])\n",
    "\n",
    "\n",
    "# Convert RUNTIME to numeric, fill NaN with median\n",
    "df['runtime'] = df['runtime'].fillna(df['runtime'].median())\n",
    "df[['runtime_scaled']] = scaler.fit_transform(df[['runtime']])\n",
    "\n",
    "\n",
    "# Convert ADULT to binary (1 for True, 0 for False)\n",
    "# actually is statistically releveant, as almost 10 % are adult movies\n",
    "df['adult'] = df['adult'].astype(bool).astype(int)\n",
    "\n",
    "\n",
    "# One Hot Encoding for ORIGINAL_LANGUAGE\n",
    "df = pd.get_dummies(df, columns=['original_language'], prefix='lang', drop_first=True)\n",
    "\n",
    "\n",
    "# Min Max Scaling for POPULARITY\n",
    "df[['popularity_scaled']] = scaler.fit_transform(df[['popularity']])\n",
    "\n",
    "\n",
    "# Extracting features for genres with MultiLabelBinarizer in function above\n",
    "genre_features = [col for col in df.columns if col.startswith('has_')]\n",
    "\n",
    "# Final list of features\n",
    "feature_cols = [\n",
    "    'vote_count_log',\n",
    "    'status_released',\n",
    "    'release_year',\n",
    "    'budget_scaled',\n",
    "    'revenue_scaled',\n",
    "    'runtime_scaled',\n",
    "    'adult',\n",
    "    'popularity_scaled',\n",
    "    #'spoken_languages' â€” handled separately\n",
    "] + genre_features + [col for col in df.columns if col.startswith('lang_')]\n",
    "\n",
    "\n",
    "features = df[feature_cols]\n",
    "#target = df['vote_average']\n",
    "\n",
    "\n",
    "\n",
    "# fill the Not a Number values with 0\n",
    "features = features.fillna(0)"
   ],
   "id": "b1d8e065-73e0-4d1f-8e13-30f522858357",
   "outputs": [],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:53.534919Z",
     "start_time": "2025-08-05T10:50:53.178876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split Data into Training, Validation, and Test Sets\n",
    "# We will use 70% for training, 20% for validation, 10% for tests\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "\n",
    "# Splitting the Data into train and temporary sets (70% train, 30% temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    # X_train : features\n",
    "    # X_temp : also features, 30 percent of the data\n",
    "    # y_train : target\n",
    "    # y_temp : still 30 percent of the data, but not features -> target values\n",
    "    features, target,\n",
    "    test_size=0.30,\n",
    "    )\n",
    "\n",
    "# Splitting the Temp set into validation and test sets (50% of temp each)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=1/3,\n",
    ")\n",
    "\n",
    "\n"
   ],
   "id": "73e95fd983f614e1",
   "outputs": [],
   "execution_count": 212
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:53.542232Z",
     "start_time": "2025-08-05T10:50:53.539665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "print(\"Training target shape:\", y_train.shape)\n",
    "print(\"Validation target shape:\", y_val.shape)\n",
    "print(\"Test target shape:\", y_test.shape)\n"
   ],
   "id": "676b4bd04a02f89f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (886443, 183)\n",
      "Validation set shape: (253270, 183)\n",
      "Test set shape: (126635, 183)\n",
      "Training target shape: (886443,)\n",
      "Validation target shape: (253270,)\n",
      "Test target shape: (126635,)\n"
     ]
    }
   ],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:53.632558Z",
     "start_time": "2025-08-05T10:50:53.556259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for object (non-numeric) dtypes\n",
    "print(features.dtypes[features.dtypes == 'object'])\n",
    "\n",
    "# Check for missing values\n",
    "print(\"NaNs in features:\", features.isna().sum().sum())\n",
    "print(\"NaNs in target:\", target.isna().sum())"
   ],
   "id": "9e5ae133caafb087",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: object)\n",
      "NaNs in features: 0\n",
      "NaNs in target: 0\n"
     ]
    }
   ],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:57.885153Z",
     "start_time": "2025-08-05T10:50:53.637238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "# import model to be used\n",
    "model = LinearRegression()\n",
    "\n",
    "# by fit -> train model on data set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# produce a prediction on validation and test sets\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Look at the performance\n",
    "\n",
    "# RÂ² score\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Mean Squared Error\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"ðŸ“Š Validation R2:\", r2_val)\n",
    "print(\"----------------------\")\n",
    "print(\"ðŸ“Š Test R2:\", r2_test)\n",
    "print(\"----------------------\")\n",
    "print(\"ðŸ“‰ Validation MSE:\", mse_val)\n",
    "print(\"----------------------\")\n",
    "print(\"ðŸ“‰ Test MSE:\", mse_test)\n",
    "print(\"----------------------\")"
   ],
   "id": "4dd36c906333cb5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Validation R2: 0.48915923171148146\n",
      "----------------------\n",
      "ðŸ“Š Test R2: 0.4886387421728049\n",
      "----------------------\n",
      "ðŸ“‰ Validation MSE: 4.435183300952036\n",
      "----------------------\n",
      "ðŸ“‰ Test MSE: 4.446892873580834\n",
      "----------------------\n"
     ]
    }
   ],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:57.924736Z",
     "start_time": "2025-08-05T10:50:57.896581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Create a DataFrame with predictions, actuals, and titles\n",
    "results = pd.DataFrame({\n",
    "\n",
    "    # take the correct movie title\n",
    "    'title': df.loc[X_test.index, 'title'],\n",
    "\n",
    "    'predicted_rating': y_test_pred,\n",
    "\n",
    "    'actual_rating': y_test\n",
    "})\n",
    "\n",
    "# Round values for easier reading\n",
    "results['predicted_rating'] = results['predicted_rating'].round(2)\n",
    "results['actual_rating'] = results['actual_rating'].round(2)\n",
    "\n",
    "res_non_zero = results[results['actual_rating'] > 0]\n",
    "\n",
    "# Show a random sample of 15 movies\n",
    "sample_results = res_non_zero.sample(20, random_state=42)\n",
    "\n",
    "display(sample_results)"
   ],
   "id": "12975a797b3afdff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                    title  predicted_rating  \\\n",
       "131655                                         Shutterbug              4.03   \n",
       "183969                                         Cut It Out              2.88   \n",
       "110591  10umentary: Behind the Scenes of StarKid Homec...              4.60   \n",
       "89407                                         Mexico City              5.13   \n",
       "332190                                  Mad For Vengeance              2.10   \n",
       "189294                                         Rumba Love              3.05   \n",
       "32539                                             Traders              7.91   \n",
       "335080                                               Haze              2.10   \n",
       "114786                              The Diary of Dr. Hart              4.43   \n",
       "69251                                       Mid Road Gang              6.10   \n",
       "278219                                                Toc              2.44   \n",
       "309717                                  RohovÃ­n ÄŒtverrohÃ½              2.07   \n",
       "155023                             A Trap for the General              4.13   \n",
       "245834                                  Father Knows Best              2.30   \n",
       "136118            Queen + Adam Lambert: Rock Big Ben Live              4.00   \n",
       "23596                                               House              8.82   \n",
       "190894                             The Accidental Revenge              3.01   \n",
       "8759                                            The Women             10.69   \n",
       "213751                             Molly & Wors The Movie              2.87   \n",
       "186382                                          The Guest              3.36   \n",
       "\n",
       "        actual_rating  \n",
       "131655           4.50  \n",
       "183969           5.50  \n",
       "110591           6.30  \n",
       "89407            4.80  \n",
       "332190           2.00  \n",
       "189294           7.50  \n",
       "32539            6.19  \n",
       "335080          10.00  \n",
       "114786           5.20  \n",
       "69251            6.70  \n",
       "278219           5.00  \n",
       "309717           8.00  \n",
       "155023           5.70  \n",
       "245834           5.50  \n",
       "136118           9.50  \n",
       "23596            4.69  \n",
       "190894           9.50  \n",
       "8759             5.04  \n",
       "213751           6.00  \n",
       "186382           5.00  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>actual_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131655</th>\n",
       "      <td>Shutterbug</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183969</th>\n",
       "      <td>Cut It Out</td>\n",
       "      <td>2.88</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110591</th>\n",
       "      <td>10umentary: Behind the Scenes of StarKid Homec...</td>\n",
       "      <td>4.60</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89407</th>\n",
       "      <td>Mexico City</td>\n",
       "      <td>5.13</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332190</th>\n",
       "      <td>Mad For Vengeance</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189294</th>\n",
       "      <td>Rumba Love</td>\n",
       "      <td>3.05</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32539</th>\n",
       "      <td>Traders</td>\n",
       "      <td>7.91</td>\n",
       "      <td>6.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335080</th>\n",
       "      <td>Haze</td>\n",
       "      <td>2.10</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114786</th>\n",
       "      <td>The Diary of Dr. Hart</td>\n",
       "      <td>4.43</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69251</th>\n",
       "      <td>Mid Road Gang</td>\n",
       "      <td>6.10</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278219</th>\n",
       "      <td>Toc</td>\n",
       "      <td>2.44</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309717</th>\n",
       "      <td>RohovÃ­n ÄŒtverrohÃ½</td>\n",
       "      <td>2.07</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155023</th>\n",
       "      <td>A Trap for the General</td>\n",
       "      <td>4.13</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245834</th>\n",
       "      <td>Father Knows Best</td>\n",
       "      <td>2.30</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136118</th>\n",
       "      <td>Queen + Adam Lambert: Rock Big Ben Live</td>\n",
       "      <td>4.00</td>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23596</th>\n",
       "      <td>House</td>\n",
       "      <td>8.82</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190894</th>\n",
       "      <td>The Accidental Revenge</td>\n",
       "      <td>3.01</td>\n",
       "      <td>9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>The Women</td>\n",
       "      <td>10.69</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213751</th>\n",
       "      <td>Molly &amp; Wors The Movie</td>\n",
       "      <td>2.87</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186382</th>\n",
       "      <td>The Guest</td>\n",
       "      <td>3.36</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T10:50:57.931339Z",
     "start_time": "2025-08-05T10:50:57.929978Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "abfc1b68eed7096e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
